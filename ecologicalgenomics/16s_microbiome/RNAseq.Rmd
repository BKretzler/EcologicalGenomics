---
title: "RNAseq"
author: "Bailey Kretzler"
date: "9/29/2021"
output: html_document
---

### Looking at Acartia hudsonica
  * calanoid copepode
  * cold water adapted
  * coastal, abundant in NE coast
  * important organisms in coastal ecosystems
    * both predator and prey
  * body sizes have been obsevered to decrease in warmer temps 
  * experimentally evolved to 4 conditions:
    * ocean acidification
    * ocean warming
    * ocean acidification and warming
    * ambient 
  * collected from Long Island Sound CT
    * reared for 3 gens
  * 3 replicate vessels for each treatment
    * ~4000 copepods per vessel
  * 50 adults collected from F0, F2, F4, and F11
    * used for RNA 
    * flash frozen in lN2
  * sequenced using Novoseq
  * not all generations are present for all treatments
    * unequal replication
    * some with replication that is too low
  * treatment labels:
    * AA - ambient
    * AH - acidification
    * HA - warming
    * HH - acidification and warming
  * F0 and F4 are present in all treatments
  * ambient and both have F11 so that's a good comparison
  
  
### What questions and hypothesis can we make with these?

1. Additive impact of acidification and warming? Do these result in similar changes in gene expression?
2. How does gene expression change across generations? How much of this is heritable? Could only do this across all 4 at F4 generation
3. How does gene expression change across time? Basically a time course to see if allele frequency and/or gene expression are headed in the same direction.
4. What is the rate at which the alleles become fixed?
5. How does expression of specific gene classes change across time? This would be cool with multiple graphs for each gene class
6. Plasticity in response for each treatment. We can compare the treatments to the ambient to figure this out and see if changes are maintained across generations.
7. Check completeness of the transcriptome based on a set of housekeeping/core genes for eukaryotes. Isn't taxa specific.

### Process:

* quality control using FastQC and/or MultiQC
*cleaning with trimmomatic (trim, filter, headcrop)

Go back and forth between these two processes


### Project directory:

```
/data/project_data/RNAseq/fastqc/

```

This is where all of the files live that folks extracted on Wednesday (9/29)

### Trimmomatic (done for us)

This cleans up the reads for each file/sequence. Uses a forloop to clean up each file. Can specify the number of threads to use (the CPUs to use to run this). Illumina clip needs to be done early - it points your loop to the adapter sequences. Leading is minimum quality score you want for left, trailing is the right (reverse). Sliding window specifies a quality check for the whol sequence. Millen specifies a minimum length for the sequence, gets rid of anything less than. Phred33 is standard illumina quality estimate.

Remember that all bash script start with #!/bin/bash - tells comp that the code is in bash.
  * to make a script you use `vim test.sh`
  * then we do `i` for insert   
  * `#!/bin/bash` at beginning of sript
  * we can then code in bash within this script and save it (bin = binary)
  * to save `:wq!` - says write the file and quit and yes i def want to do this
  * to make executable back in terminal `chmod u+x test.sh` - says let user execute the script
  * to execute `./test.sh`
  * but really it's better to do this as a text file and then load it in to 


### Running multiqc - only needs done once:

```
cd /data/project_data/RNAseq/cleandata

multiqc .

```

This pulls all of the files together into one html. We can then move this to our computers to check it


### Run fastqc on cleaned reads:

```
cd /data/project_data/RNAseq/cleandata
fastqc FILENAME*.fq.gz

--outdir=/data/project_data/RNAseq/fastqc/clean

```
then we run mutliqc again on the cleaned reads.

HTMLs can then be copied to the desktop and viewed to compare cleaned and uncleaned reads.

What do we notice about ours?:

  * lots of duplicate sequences (50%) - better if this is around 10-20%
    * this could be from PCR duplicates
    * can be a biological duplicate (high expression) but that is less likely
    * this is happening across all samples
  *the irregularity in the proportion of bases is still present
    * it may not be an adapter
    * could still be due to the hexamer primers from library prep
      * leads to over amplification of certain primers
    * can be avoided by doing a head crop in trimmomatic
      * cuts off the first 12 bases
      * this needs to come before all other quality filters
      
From our cleaned fastq we can now do transcriptome assembly 
  * usually with trinity but it's currently having issues 
  * Then we map out reads from the fastq to the transcriptome
    * alignment free mapping - salmon does this
      * uses kmers to find probability of where a read will fall
    * alignment mapping - bowtie2 + BWA do this
      * generates a .sam file
      * takes longer cause you have to align all the reads
      * very robust
  * requires high quality clean data for transcriptome and mapping
    * so clean data is very important
  * if you have a genome you can map to the genome
    * but have to consider intron exon boundaries
    * STAR genome aligner can be helpful here
  * from the aligner we are hoping to obtain a count file with counts of each transcript for each sample
    * then we use DESeq2 or EdgeR to analyze counts
    
Right now the mapping quality is low when mapped either to the transcriptome with bidger + salmon, and when using another acartia species (tonsa) + salmon (2.5%). Could be something wrong with the assembly or with the alignment with salmon. 

AS A RESULT: we will be working with the acartia tonsa 

### Use salmon to quantify transcript abundance:

First we index the reference transcriptome. This is only done once and has been done for us:

```
cd /data/project_data/RNAseq/assembly/

conda activate salmon

salmon index -t Bridger.fasta -i hudsonica_index -p 8


```

  * *NOTE - p inidicates how many threads/cpus to use*
  * this also uses bridger instead of trinity which is the standard  + higher quality


Then we start the quantification with the below code in a SCREEN

```
conda activate salmon
cd /data/project_data/RNAseq/cleandata
salmon quant -i /data/project_data/RNAseq/assembly/hudsonica_index -l A \
  -1 AA_F0_Rep1_1.qc.fq.gz AA_F4_Rep3_1.qc.fq.gz HA_F0_Rep1_1.qc.fq.gz HH_F0_Rep2_1.qc.fq.gz AA_F0_Rep2_1.qc.fq.gz AH_F0_Rep1_1.qc.fq.gz HA_F0_Rep2_1.qc.fq.gz HH_F0_Rep3_1.qc.fq.gz AA_F0_Rep3_1.qc.fq.gz AH_F0_Rep2_1.qc.fq.gz HA_F0_Rep3_1.qc.fq.gz HH_F11_Rep1_1.qc.fq.gz AA_F11_Rep1_1.qc.fq.gz AH_F0_Rep3_1.qc.fq.gz HA_F2_Rep1_1.qc.fq.gz HH_F11_Rep2_1.qc.fq.gz AA_F11_Rep2_1.qc.fq.gz AH_F2_Rep1_1.qc.fq.gz HA_F2_Rep2_1.qc.fq.gz HH_F11_Rep3_1.qc.fq.gz AA_F11_Rep3_1.qc.fq.gz AH_F2_Rep2_1.qc.fq.gz HA_F2_Rep3_1.qc.fq.gz HH_F4_Rep1_1.qc.fq.gz AA_F2_Rep2_1.qc.fq.gz AH_F2_Rep3_1.qc.fq.gz HA_F4_Rep1_1.qc.fq.gz HH_F4_Rep2_1.qc.fq.gz AA_F2_Rep3_1.qc.fq.gz AH_F4_Rep1_1.qc.fq.gz HA_F4_Rep2_1.qc.fq.gz HH_F4_Rep3_1.qc.fq.gz AA_F4_Rep1_1.qc.fq.gz AH_F4_Rep2_1.qc.fq.gz HA_F4_Rep3_1.qc.fq.gz AA_F4_Rep2_1.qc.fq.gz AH_F4_Rep3_1.qc.fq.gz HH_F0_Rep1_1.qc.fq.gz \
  -2 AA_F0_Rep1_2.qc.fq.gz AA_F4_Rep3_2.qc.fq.gz HA_F0_Rep1_2.qc.fq.gz HH_F0_Rep2_2.qc.fq.gz AA_F0_Rep2_2.qc.fq.gz AH_F0_Rep1_2.qc.fq.gz HA_F0_Rep2_2.qc.fq.gz HH_F0_Rep3_2.qc.fq.gz AA_F0_Rep3_2.qc.fq.gz AH_F0_Rep2_2.qc.fq.gz HA_F0_Rep3_2.qc.fq.gz HH_F11_Rep1_2.qc.fq.gz AA_F11_Rep1_2.qc.fq.gz AH_F0_Rep3_2.qc.fq.gz HA_F2_Rep1_2.qc.fq.gz HH_F11_Rep2_2.qc.fq.gz AA_F11_Rep2_2.qc.fq.gz AH_F2_Rep1_2.qc.fq.gz HA_F2_Rep2_2.qc.fq.gz HH_F11_Rep3_2.qc.fq.gz AA_F11_Rep3_2.qc.fq.gz AH_F2_Rep2_2.qc.fq.gz HA_F2_Rep3_2.qc.fq.gz HH_F4_Rep1_2.qc.fq.gz AA_F2_Rep2_2.qc.fq.gz AH_F2_Rep3_2.qc.fq.gz HA_F4_Rep1_2.qc.fq.gz HH_F4_Rep2_2.qc.fq.gz AA_F2_Rep3_2.qc.fq.gz AH_F4_Rep1_2.qc.fq.gz HA_F4_Rep2_2.qc.fq.gz HH_F4_Rep3_2.qc.fq.gz AA_F4_Rep1_2.qc.fq.gz AH_F4_Rep2_2.qc.fq.gz HA_F4_Rep3_2.qc.fq.gz AA_F4_Rep2_2.qc.fq.gz AH_F4_Rep3_2.qc.fq.gz HH_F0_Rep1_2.qc.fq.gz \
  --validateMappings -o /data/project_data/RNAseq/salmon/transcripts_quant

```
  * there are other options for using salmon on their git hub (https://salmon.readthedocs.io/en/latest/salmon.html#description-of-important-options)
  
  
SKIP A BUNCH OF STEPS TO PLAYING WITH DATA IN R

A tonsa files grabbed from the server

### data a file imports

```{r}
#---------------------------------------------------------#
#                 Set working directory                      
#---------------------------------------------------------#

#set working directory
setwd("C:/Users/kretz/R/EcologicalGenomics/")

#check to make sure it is correct
getwd()
#---------------------------------------------------------#
#                      Load packages                      
#---------------------------------------------------------#
library(rlang)
library(RSQLite)
library(DESeq2)
library(dplyr)
library(tidyr)
library(ggplot2)
library(scales)
library(ggpubr)
library(wesanderson)
library(vsn) 

#---------------------------------------------------------#
#                      Load in the file                       
#---------------------------------------------------------#

########################
#files are not loading
########################

## counts mat
countsTable <- read.table(file = "DE_counts_F1.txt",header = T, row.names =1)
# row.names are column 1
head(countsTable)

## Round
countsTableRound <- round(countsTable)  #this is like the table.qza/v in qiime - a table of counts
head(countsTableRound)


  #columns:
    #AAAA = ambient transplanted to ambient
    #AAHH = ambient transplanted into high heat high co2?
    #HHAA = high heat high co2 transplanted into ambient
    #HHHH = high heat high co2 transplanted into high heat high co2
  #row names:
    #graph (map?) identifiers from trinity 
    #aka genes basically gene identifiers (or transcript??)
  #cells:
    #counts of each transcript
    #rounded, they are decimals bc they are actually probabilities


## import sample decription table
cons <- read.delim(file = "RT_tonsa_F1_samples.txt", 
                   header = T, 
                   stringsAsFactors = T)    #this is like the metadata in qiime (pyc_manifest)
head(cons)

  #rows:
    #samples as labeled above for count cols
  # columns
    #group/treatment
    #line - aka original treatment
    #environment- aka transplant environment

#---------------------------------------------------------#
#                      exploring data                      
#---------------------------------------------------------#

#------------------Reads per sample -----------------------#
                     


##total number or reads for each sample
colSums(countsTableRound)

##average number of reads per sample
mean(colSums(countsTableRound))

##plot the total reads for each sample
barplot(colSums(countsTableRound),names.arg = colnames(countsTableRound), cex.names = 0.6, las = 3, ylim = c(0,20000000))
abline(h = mean(colSums(countsTableRound)), col ="blue", lwd = 2)

    #Generally all the samples look pretty good, all in the range of 10 to 20 million and mostly on the higher side


#------------------reads per gene-----------------------#


##average number of counts per gene
rowSums(countsTableRound)

## mean of counts per gene
mean(rowSums(countsTableRound))

#median of counts per gene
median(rowSums(countsTableRound))

#check out distribution  - log transformed
hist(apply(countsTableRound, 1, mean), xlim = c(0,1000), breaks = 10000)
hist(log(apply(countsTableRound, 1, mean)))

    # have to zoom in or log transform
    # there are a lot in the low range

apply(countsTableRound, 2, mean) #2 = action across cols
apply(countsTableRound, 1, mean) #1 = action across rows

#---------------------------------------------------------#
#             define DESeq object + exp design                      
#---------------------------------------------------------#

##create the DESeq object from the data we loaded in 
dds <- DESeqDataSetFromMatrix(countData = countsTableRound, 
                              colData = cons, 
                              design = ~line + environment + line:environment)

      #using the tilda to deine the design
      # says the design it line and environment plus their interaction
      # models the counts by everything after the tilda (~)
      # DESeq uses a negative binomial distribution, useful for counts and long dispersion (skew/spread)

dim(dds)

## filter out genes with too few reads
  #keep genes with average > 10 reads per sample
  #when we do this we rewrite the object and need to reload the object to revert to original dimensions

dds <- dds[rowSums(counts(dds))>160]
dim(dds)


#---------------------------------------------------------#
#                      run DESeq model                      
#---------------------------------------------------------#

##this tests for differential expression
dds <-DESeq(dds)
  #size factors = across samples
  #dispersions = across transcripts


## list the results:
resultsNames(dds) 

    # [1] "Intercept"                  "line_combined_vs_ambient"  
    # [3] "environment_HH_vs_AA"       "linecombined.environmentHH"

#---------------------------------------------------------#
#                      PCA of data                      
#---------------------------------------------------------#

##lets make a PCA of the patterns of global expression

##create vsd object
vsd <- vst(dds, blind = F)

##create data object for PCA
data <- plotPCA(vsd, intgroup = c("line", "environment"), returnData = TRUE)
    #generates positions on PCA for each sample based on grouping

## create percentVar object for PCA
percentVar <- round(100*attr(data, "percentVar"))
    #what does this do????
    #generates the amount of variance explained by each PCA

## plotting the PCA
ggplot(data, aes(PC1, PC2, color = environment, shape = line)) + 
  geom_point(size = 4, alpha = 0.85) + 
  xlab(paste0("PC1: ", percentVar[1], "%variance")) + 
  ylab(paste0("PC2: ", percentVar[2], "%variance")) + 
  theme_bw()+
  scale_colour_viridis_d()

  # we see a clustering of both environment and line
    

#---------------------------------------------------------#
#           order and summarize specific contrasts                      
#---------------------------------------------------------#

#looking at results from the interactions

##create matrix of dds object results + order by p val
resInt <- results(dds, alpha = 0.05)
resInt <- resInt[order(resInt$padj),]
head(resInt)

      #     log2 fold change (MLE): linecombined.environmentHH 
      # Wald test p-value: linecombined.environmentHH 
      # DataFrame with 6 rows and 6 columns
      #                         baseMean log2FoldChange     lfcSE      stat
      #                        <numeric>      <numeric> <numeric> <numeric>
      # TRINITY_DN115950_c0_g1   2245.97        4.05237  0.358490   11.3040
      # TRINITY_DN131561_c0_g1   3375.99        4.64570  0.439847   10.5621
      # TRINITY_DN137662_c0_g1  16743.23        4.90200  0.474583   10.3291
      # TRINITY_DN149842_c8_g4  25971.82        4.27274  0.420809   10.1536
      # TRINITY_DN129565_c0_g3  24258.76        4.30553  0.426037   10.1060
      # TRINITY_DN129401_c0_g5  11712.31        4.46355  0.446094   10.0059
      #                             pvalue        padj
      #                          <numeric>   <numeric>
      # TRINITY_DN115950_c0_g1 1.25396e-29 2.99446e-25
      # TRINITY_DN131561_c0_g1 4.46620e-26 5.33264e-22
      # TRINITY_DN137662_c0_g1 5.20658e-25 4.14444e-21
      # TRINITY_DN149842_c8_g4 3.19275e-24 1.90607e-20
      # TRINITY_DN129565_c0_g3 5.19661e-24 2.48190e-20
      # TRINITY_DN129401_c0_g5 1.43650e-23 5.71728e-20

## summarize this

summary(resInt)
  #output:
    # out of 24362 with nonzero total read count
    # adjusted p-value < 0.05
    # LFC > 0 (up)       : 2839, 12%
    # LFC < 0 (down)     : 1053, 4.3%
    # outliers [1]       : 9, 0.037%
    # low counts [2]     : 473, 1.9%
    # (mean count < 18)
  #16% show significant interaction effect (on expression?)

#---------------------------------------------------------#
#                 test for effect of env                      
#---------------------------------------------------------#
#USING THE LIKELIHOOD RATIO TEST

## run DESeq with line + enviornment 
    #run full model compared to te reduced
    #to test what the impact of adding environment is
dds <- DESeqDataSetFromMatrix(countData = countsTableRound, 
                              colData = cons, 
                              design = ~ line + environment)

##compare reduced model using likelihood ratio test
dds <- DESeq(dds, test="LRT", reduced=~line) #remove environment + ask which descriebs better

## List the results you've generated
resultsNames(dds) # see what results it produced - NOT RESULTS THEMSELVES

## Order and list and summarize results from specific contrasts
resEnv <- results(dds, alpha = 0.05)  #sign cut off of 0.05
resEnv <- resEnv[order(resEnv$padj),] #order by adj pval
head(resEnv)

    ########OUTPUT########
    #                      baseMean log2FoldChange     lfcSE      stat
    #                         <numeric>      <numeric> <numeric> <numeric>
    # TRINITY_DN138549_c1_g2    582.410       -1.94341  0.173407  118.0825
    # TRINITY_DN138549_c2_g12   773.349       -2.01757  0.203760   91.4210
    # TRINITY_DN150696_c2_g3    297.068        1.31754  0.163636   63.1253
    # TRINITY_DN123676_c0_g2    179.431       -2.51746  0.309813   59.1190
    # TRINITY_DN131329_c1_g1    213.660       -1.23500  0.158361   59.4117
    # TRINITY_DN105043_c0_g1    101.714       -3.94548  0.471847   57.1227
    #                              pvalue        padj
    #                           <numeric>   <numeric>
    # TRINITY_DN138549_c1_g2  1.66325e-27 3.96651e-23
    # TRINITY_DN138549_c2_g12 1.16138e-21 1.38483e-17
    # TRINITY_DN150696_c2_g3  1.93963e-15 1.54188e-11
    # TRINITY_DN123676_c0_g2  1.48423e-14 7.07917e-11
    # TRINITY_DN131329_c1_g1  1.27903e-14 7.07917e-11
    # TRINITY_DN105043_c0_g1  4.09446e-14 1.62741e-10

## Summarize the results
summary(resEnv)
      ######OUTPUT######
      # out of 24362 with nonzero total read count
      # adjusted p-value < 0.05
      # LFC > 0 (up)       : 213, 0.87%     <- log fold change > 0 - upregulated, higher in HH than AA
      # LFC < 0 (down)     : 235, 0.96%     <- log fold change < 0 - downregulated, higher in AA than HH
      # outliers [1]       : 41, 0.17%      <- outliers removed??? maybe
      # low counts [2]     : 473, 1.9%      <- low counts excluded from analysis
      # (mean count < 18)     <- definition of low counts


## remove NAs - from outliers and low counts
resEnv <- resEnv[!is.na(resEnv$padj),]


## Save genes that are significant
degsEnv <- row.names(resEnv[resEnv$padj < 0.05,]) 
degsEnv[1:5]



#---------------------------------------------------------#
#                 test for effect of line                      
#---------------------------------------------------------#
##### Same process as above

dds <- DESeqDataSetFromMatrix(countData = countsTableRound, 
                              colData = cons, 
                              design = ~ environment + line)

dds <- DESeq(dds, test="LRT", reduced=~environment)
resultsNames(dds)

resLine <- results(dds, alpha = 0.05)
resLine <- resLine[order(resLine$padj),]
head(resLine)

    # baseMean log2FoldChange     lfcSE      stat
    #                         <numeric>      <numeric> <numeric> <numeric>
    # TRINITY_DN144155_c0_g8    55.1773       -1.73551  0.199458   75.7313
    # TRINITY_DN116533_c0_g1   101.9489        3.49591  0.435406   53.9339
    # TRINITY_DN142881_c2_g11 1414.7388       -1.43499  0.199146   49.9265
    # TRINITY_DN140379_c0_g5    49.4278        1.69441  0.272190   37.9057
    # TRINITY_DN140379_c0_g6   220.5736        1.86590  0.297107   37.1901
    # TRINITY_DN138009_c0_g2    88.4193        2.12835  0.354530   33.7159
    #                              pvalue        padj
    #                           <numeric>   <numeric>
    # TRINITY_DN144155_c0_g8  3.25019e-18 7.13710e-14
    # TRINITY_DN116533_c0_g1  2.07352e-13 2.27662e-09
    # TRINITY_DN142881_c2_g11 1.59616e-12 1.16834e-08
    # TRINITY_DN140379_c0_g5  7.42487e-10 4.07607e-06
    # TRINITY_DN140379_c0_g6  1.07155e-09 4.70602e-06
    # TRINITY_DN138009_c0_g2  6.37772e-09 2.00069e-05


summary(resLine)

    # out of 21959 with nonzero total read count
    # adjusted p-value < 0.05
    # LFC > 0 (up)       : 72, 0.33%
    # LFC < 0 (down)     : 154, 0.7%
    # outliers [1]       : 0, 0%
    # low counts [2]     : 0, 0%
    # (mean count < 25)


resLine <- resLine[!is.na(resLine$padj),]

degsline <- row.names(resLine[resLine$padj < 0.05,])
degsline[1:5]


#---------------------------------------------------------#
#                  test for effect of int                      
#---------------------------------------------------------#
#### Same process as above


dds <- DESeqDataSetFromMatrix(countData = countsTableRound, 
                              colData = cons, 
                              design = ~ environment + line + environment:line)

dds <- DESeq(dds, test="LRT", reduced=~environment + line)
resultsNames(dds)

resInt <- results(dds, alpha = 0.05)
resInt <- resInt[order(resInt$padj),]
head(resInt)

    # baseMean log2FoldChange     lfcSE      stat
    #                        <numeric>      <numeric> <numeric> <numeric>
    # TRINITY_DN115950_c0_g1   2245.97        4.05237  0.358490  118.7642
    # TRINITY_DN131561_c0_g1   3375.99        4.64570  0.439847  101.4199
    # TRINITY_DN137662_c0_g1  16743.23        4.90200  0.474583   95.9225
    # TRINITY_DN149842_c8_g4  25971.82        4.27274  0.420809   94.8761
    # TRINITY_DN129565_c0_g3  24258.76        4.30553  0.426037   93.8792
    # TRINITY_DN129401_c0_g5  11712.31        4.46355  0.446094   91.5220
    #                             pvalue        padj
    #                          <numeric>   <numeric>
    # TRINITY_DN115950_c0_g1 1.17951e-27 2.76100e-23
    # TRINITY_DN131561_c0_g1 7.44127e-24 8.70926e-20
    # TRINITY_DN137662_c0_g1 1.19473e-22 9.32205e-19
    # TRINITY_DN149842_c8_g4 2.02680e-22 1.18608e-18
    # TRINITY_DN129565_c0_g3 3.35378e-22 1.57010e-18
    # TRINITY_DN129401_c0_g5 1.10356e-21 4.30535e-18
   

summary(resInt)

    # out of 23408 with nonzero total read count
    # adjusted p-value < 0.05
    # LFC > 0 (up)       : 2802, 12%
    # LFC < 0 (down)     : 1052, 4.5%
    # outliers [1]       : 0, 0%
    # low counts [2]     : 0, 0%
    # (mean count < 20)
        #about the same as the WALD test
resInt <- resInt[!is.na(resInt$padj),]

degsInt <- row.names(resInt[resInt$padj < 0.05,])

#---------------------------------------------------------#
#                   plot individual genes                      
#---------------------------------------------------------#

## Known environment gene
d <-plotCounts(dds, gene="TRINITY_DN138549_c1_g2", intgroup = (c("line","environment")), returnData=TRUE)
d

p <-ggplot(d, aes(x=environment, y=count, color=line, shape=line, group=line)) + 
  theme_bw() + theme(text = element_text(size=18), panel.grid.major=element_line(colour="grey")) + scale_colour_viridis_d()
p <- p + geom_point(position=position_jitter(w=0.2,h=0), size=3)
p <- p + stat_summary(fun = mean, geom = "line")
p <- p + stat_summary(fun = mean, geom = "point", size=5, alpha=0.7)
p

#follows expected environment trend!! 
    #both high in one env (AA)
    #both low in other (HH)

#---------------------------------------------------------#
## Known line gene
d <-plotCounts(dds, gene="TRINITY_DN144155_c0_g8", intgroup = (c("line","environment")), returnData=TRUE)
d

p <-ggplot(d, aes(x=environment, y=count, color=line, shape=line, group=line)) + 
  theme_bw() + theme(text = element_text(size=18), panel.grid.major=element_line(colour="grey")) + scale_colour_viridis_d()
p <- p + geom_point(position=position_jitter(w=0.2,h=0), size=3)
p <- p + stat_summary(fun = mean, geom = "line")
p <- p + stat_summary(fun = mean, geom = "point", size=5, alpha=0.7)
p

#more or less the expected line effect
  # consistent between both envs for ambient and combine lines
  # parallel (sort of) but apart


#---------------------------------------------------------#
## Known interaction gene
d <-plotCounts(dds, gene="TRINITY_DN115950_c0_g1", intgroup = (c("line","environment")), returnData=TRUE)
d

p <-ggplot(d, aes(x=environment, y=count, color=line, shape=line, group=line)) + 
  theme_bw() + theme(text = element_text(size=18), panel.grid.major=element_line(colour="grey")) + scale_colour_viridis_d()
p <- p + geom_point(position=position_jitter(w=0.2,h=0), size=3)
p <- p + stat_summary(fun = mean, geom = "line")
p <- p + stat_summary(fun = mean, geom = "point", size=5, alpha=0.7) 
p

#expected interaction effect
  #lines crisscross
  # higher expression in home environment
  # may also be lower in home environment


#---------------------------------------------------------#
#                      plot venn diagram                      
#---------------------------------------------------------#
library(eulerr)

# Total
length(degsEnv)  # 448 <- total # genes sig in env
length(degsline)  # 226 <- total # genes sig in line
length(degsInt)  # 3854 <- total # genes sig in int

# Intersections
length(intersect(degsEnv,degsline))  # 37 <- total # genes sig @ intersect of line + env
length(intersect(degsEnv,degsInt))  # 44 <- total # genes sig @ intersect of int + env
length(intersect(degsInt,degsline))  # 34 <- total # genes sig @ intersect of line + int

intEL <- intersect(degsEnv,degsline) <- total # genes sig @ intersect of line + env
length(intersect(degsInt,intEL)) # 7 <- total # genes sig @ intersect of line + env + int using object assigned above

# Number unique
448-44-37-7 # 360   <- total # genes sig and unique to env
226-37-34-7 # 148   <- total # genes sig and unique to line
3854-44-34-7 # 3769  <- total # genes sig and unique to int

#create a "fit" using these seven vals
fit1 <- euler(c("Env" = 360, "Line" = 148, "Interaction" = 3769, "Env&Line" = 37, "Env&Interaction" = 44, "Line&Interaction" = 34, "Env&Line&Interaction" = 7))

#plot these values in a venn diagram
plot(fit1,  lty = 1:3, quantities = TRUE)

#same but transparent
plot(fit1, quantities = TRUE, fill = "transparent",
     lty = 1:3,
     labels = list(font = 4))

# this shows us the overlap between genes that are significant for each model
  # a lot are specific to the interaction/transplant
  # only 7 shared between all models
  # some (34 -44) shared between 2 of the models

#---------------------------------------------------------#
#                      plotting heat map                      
#---------------------------------------------------------#
# Heatmap of top 20 genes sorted by pvalue

library(pheatmap)

# By interaction

##extract top 20 genes
topgenes <- head(rownames(resInt),20)

##run stabilization on top genes
mat <- assay(vsd)[topgenes,]

##scale based on rowmeans (normalize)
mat <- mat - rowMeans(mat)

## create data frame to be able to label 
df <- as.data.frame(colData(dds)[,c("line","environment")])

## use normalize matrix to plot by df annotation col
  #creates heat map
pheatmap(mat, annotation_col=df)

# By line

topgenes <- head(rownames(resLine),20)
mat <- assay(vsd)[topgenes,]
mat <- mat - rowMeans(mat)
df <- as.data.frame(colData(dds)[,c("line","environment")])
pheatmap(mat, annotation_col=df)


# By env

topgenes <- head(rownames(resEnv),20)
mat <- assay(vsd)[topgenes,]
mat <- mat - rowMeans(mat)
df <- as.data.frame(colData(dds)[,c("line","environment")])
pheatmap(mat, annotation_col=df)


```
  
  



    
    
    
    
    
    
    
    
  